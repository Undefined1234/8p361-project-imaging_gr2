{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Conv2DTranspose\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# the size of the images in the PCAM dataset\n",
    "IMAGE_SIZE = 96\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pcam_generators(base_dir, train_batch_size=32, val_batch_size=32):\n",
    "\n",
    "     # dataset parameters\n",
    "     TRAIN_PATH = os.path.join(base_dir, 'train+val', 'train')\n",
    "     VALID_PATH = os.path.join(base_dir, 'train+val', 'valid')\n",
    "\n",
    "     RESCALING_FACTOR = 1./255\n",
    "     \n",
    "     # instantiate data generators\n",
    "     datagen = ImageDataGenerator(rescale=RESCALING_FACTOR)\n",
    "\n",
    "     train_gen = datagen.flow_from_directory(TRAIN_PATH,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=train_batch_size,\n",
    "                                             class_mode='input')\n",
    "\n",
    "     val_gen = datagen.flow_from_directory(VALID_PATH,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=val_batch_size,\n",
    "                                             class_mode='input',\n",
    "                                             shuffle=False)\n",
    "     \n",
    "     return train_gen, val_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen, val_gen = get_pcam_generators('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "def autoencoder(layers = 1):\n",
    "    for i in range(layers):\n",
    "        model.add(Conv2D(64, (3,3), activation='relu', padding='same', input_shape=(96,96,3)))\n",
    "        model.add(MaxPool2D((2,2), padding='same'))\n",
    "\n",
    "        model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "        model.add(MaxPool2D((2,2), padding='same'))\n",
    "\n",
    "        model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "        model.add(MaxPool2D((2,2), padding='same'))\n",
    "\n",
    "        model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "        model.add(UpSampling2D((2,2)))\n",
    "\n",
    "        model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "        model.add(UpSampling2D((2,2)))\n",
    "        \n",
    "        model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "        model.add(UpSampling2D((2,2)))\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    autoencoder()\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "get_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen, val_gen = get_pcam_generators('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 96, 96, 64)\n",
      "(None, 48, 48, 64)\n",
      "(None, 48, 48, 32)\n",
      "(None, 24, 24, 32)\n",
      "(None, 24, 24, 32)\n",
      "(None, 12, 12, 32)\n",
      "(None, 12, 12, 32)\n",
      "(None, 24, 24, 32)\n",
      "(None, 24, 24, 32)\n",
      "(None, 48, 48, 32)\n",
      "(None, 48, 48, 64)\n",
      "(None, 96, 96, 64)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'binary_crossentropy/mul' defined at (most recent call last):\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\asyncio\\windows_events.py\", line 316, in run_forever\n      super().run_forever()\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\20212059\\AppData\\Local\\Temp\\ipykernel_15460\\756188063.py\", line 21, in <module>\n      history = model.fit(train_gen, steps_per_epoch=train_steps,\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n      return self.compiled_loss(\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\losses.py\", line 272, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\losses.py\", line 2162, in binary_crossentropy\n      backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\backend.py\", line 5685, in binary_crossentropy\n      bce = target * tf.math.log(output + epsilon())\nNode: 'binary_crossentropy/mul'\nrequired broadcastable shapes\n\t [[{{node binary_crossentropy/mul}}]] [Op:__inference_train_function_2247]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m train_steps \u001b[38;5;241m=\u001b[39m train_gen\u001b[38;5;241m.\u001b[39mn\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mtrain_gen\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[0;32m     19\u001b[0m val_steps \u001b[38;5;241m=\u001b[39m val_gen\u001b[38;5;241m.\u001b[39mn\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mval_gen\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[1;32m---> 21\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'binary_crossentropy/mul' defined at (most recent call last):\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\asyncio\\windows_events.py\", line 316, in run_forever\n      super().run_forever()\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\20212059\\AppData\\Local\\Temp\\ipykernel_15460\\756188063.py\", line 21, in <module>\n      history = model.fit(train_gen, steps_per_epoch=train_steps,\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n      return self.compiled_loss(\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\losses.py\", line 272, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\losses.py\", line 2162, in binary_crossentropy\n      backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\Users\\20212059\\.conda\\envs\\8p361\\lib\\site-packages\\keras\\backend.py\", line 5685, in binary_crossentropy\n      bce = target * tf.math.log(output + epsilon())\nNode: 'binary_crossentropy/mul'\nrequired broadcastable shapes\n\t [[{{node binary_crossentropy/mul}}]] [Op:__inference_train_function_2247]"
     ]
    }
   ],
   "source": [
    "# save the model and weights\n",
    "model_name = 'my_first_cnn_model'\n",
    "model_filepath = model_name + '.json'\n",
    "weights_filepath = model_name + '_weights.hdf5'\n",
    "\n",
    "model_json = model.to_json() # serialize model to JSON\n",
    "with open(model_filepath, 'w') as json_file:\n",
    "    json_file.write(model_json) \n",
    "\n",
    "\n",
    "# define the model checkpoint and Tensorboard callbacks\n",
    "checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "tensorboard = TensorBoard(os.path.join('logs', model_name))\n",
    "callbacks_list = [checkpoint, tensorboard]\n",
    "\n",
    "\n",
    "# train the model\n",
    "train_steps = train_gen.n//train_gen.batch_size\n",
    "val_steps = val_gen.n//val_gen.batch_size\n",
    "\n",
    "history = model.fit(train_gen, steps_per_epoch=train_steps, \n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps,\n",
    "                    epochs=3,\n",
    "                    shuffle=True,\n",
    "                    callbacks=callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "8p361",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
