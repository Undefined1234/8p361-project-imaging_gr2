{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9707e9a7",
   "metadata": {},
   "source": [
    "### Training all the models for main_project_notebook.\n",
    "\n",
    "\n",
    "This notebook contains the code for training of the baseline CNN, autoencoder and the CNN with augmented data. The model weights are safed in a .hdf5 format and loaded into the main_project_notebook.ipynb file. The files that can be obtained using this code are:\n",
    "- `cnn_baseline_weights.hdf5`\n",
    "- `autoencoder_weights.hdf5`\n",
    "- `cnn_augmented_0.25_weights.hdf5`\n",
    "- `cnn_augmented_0.50_weights.hdf5`\n",
    "- `cnn_augmented_0.75_weights.hdf5`\n",
    "- `cnn_augmented_1_weights.hdf5`\n",
    "\n",
    "We provided them in the zip-file so it is not necessary to train all models.\n",
    "\n",
    "Firstly, the required libraries are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2335e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the functions and classes from main_util.py\n",
    "from main_util import get_pcam_generators\n",
    "from main_util import Model_architecture\n",
    "from main_util import Model_transform\n",
    "\n",
    "# Modelcheckpoint and tensorboard callbacks\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "# Other libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cb0ce0",
   "metadata": {},
   "source": [
    "### Instantiating data generators\n",
    "\n",
    "The PatchCAMELYON dataset is too big to fit in the working memory of most personal computers. This is why, we need to define some functions that will read the image data batch by batch, so only a single batch of images needs to be stored in memory at one time point. We can use the handy ImageDataGenerator function from the Keras API to do this. Note that the generators are defined within the function `get_pcam_generators` that returns them as output arguments. This function will later be called from the main code body. The function is located in `main_util.py`.\n",
    "\n",
    "**Before executing the code block below, do not forget to change the path where the PatchCAMELYON dataset is located (that is, the location of the folder that contains `train+val` that you previously downloaded and unpacked).**\n",
    "\n",
    "If everything is correct, the following output will be printed on screen after executing the code block:\n",
    "\n",
    "`Found 144000 images belonging to 2 classes.`\n",
    "\n",
    "`Found 16000 images belonging to 2 classes.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea39b945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataset path\n",
    "path = '../data'\n",
    "\n",
    "# Call function from main_util to load generators\n",
    "train_gen, val_gen = get_pcam_generators(path, \n",
    "                                         train_batch_size=16, \n",
    "                                         val_batch_size=16,\n",
    "                                         class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb78dac8",
   "metadata": {},
   "source": [
    "### Training the baseline CNN model\n",
    "\n",
    "In the first cell, the model name and necessary paths are defined first. The second cell builds the CNN model architecture using the `Model_architecture` class, which is located in `main_util.py`. The third cell initializes the training phase of the model. During training, the weights are stored into a .hdf5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d96e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model name and filepath for the weights\n",
    "model_name = \"cnn_baseline\"\n",
    "weights_filepath = f\"trained_models/{model_name}_weights.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9ec33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class instance is made\n",
    "model_cnn = Model_architecture()\n",
    "model_cnn.create_cnn(kernel_size=(3,3), pool_size=(4,4), first_filters=32, second_filters=64)\n",
    "model_cnn.compile_cnn(learning_rate=0.001)\n",
    "\n",
    "# Prints a summary of the model structure\n",
    "model_cnn.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db18b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model checkpoint and tensorboard callbacks\n",
    "checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "tensorboard = TensorBoard(os.path.join(\"logs\", model_name))\n",
    "callbacks_list = [checkpoint, tensorboard]\n",
    "\n",
    "# Train the model\n",
    "train_steps = train_gen.n//train_gen.batch_size//10\n",
    "val_steps = val_gen.n//val_gen.batch_size//10\n",
    "\n",
    "history = model_cnn.fit(train_gen, steps_per_epoch=train_steps,\n",
    "                        validation_data=val_gen,\n",
    "                        validation_steps=val_steps,\n",
    "                        epochs=30,\n",
    "                        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddd742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(20,7))\n",
    "\n",
    "# Make plot for accuracy\n",
    "ax[0].plot(history.history['accuracy'])\n",
    "ax[0].plot(history.history['val_accuracy'])\n",
    "ax[0].set_title('model accuracy')\n",
    "ax[0].set_ylabel('accuracy')\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[0].legend(['Train', 'Validation'], loc='upper left')\n",
    "ax[0].set_ylim([0, 1])\n",
    "\n",
    "# Make plot for loss\n",
    "ax[1].plot(history.history['loss'])\n",
    "ax[1].plot(history.history['val_loss'])\n",
    "ax[1].set_title('model loss')\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].legend(['Train', 'Validation'], loc='upper left')\n",
    "ax[1].set_ylim([0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98135116",
   "metadata": {},
   "source": [
    "### Training autoencoder model\n",
    "First, the model name and the filepath for the saved model are defined. Next, we need to construct new data generators. The training process of the autoencoder is unsupervised so the class mode of the data generators should be set to `input`. With these new generators, the autoencoder can be trained effectively. In the third cell, the model architecture is loaded. After this is done, the training phase of the autoencoder is initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c53796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model name and paths\n",
    "model_name = \"autoencoder\"\n",
    "weights_filepath = f\"trained_models/{model_name}_weights.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a432bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the data generators for unsupervised learning\n",
    "train_gen_ae, val_gen_ae = get_pcam_generators(path, \n",
    "                                               train_batch_size=16, \n",
    "                                               val_batch_size=16, \n",
    "                                               class_mode=\"input\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9196e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class instance is made\n",
    "model_ae = Model_architecture()\n",
    "model_ae.create_autoencoder(kernel_size=(3,3), pool_size=(2,2), first_filters=32, second_filters=16)\n",
    "model_ae.compile_autoencoder(learning_rate=0.001)\n",
    "\n",
    "# Prints a summary of the model structure\n",
    "model_ae.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ca1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Tensorboard callback\n",
    "checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "tensorboard = TensorBoard(os.path.join(\"logs\", model_name))\n",
    "callbacks_list = [checkpoint, tensorboard]\n",
    "\n",
    "# Train the model\n",
    "train_steps = train_gen_ae.n//train_gen_ae.batch_size\n",
    "val_steps = val_gen_ae.n//val_gen_ae.batch_size\n",
    "\n",
    "history = model_ae.fit(train_gen_ae, steps_per_epoch=train_steps,\n",
    "                        validation_data=val_gen_ae,\n",
    "                        validation_steps=val_steps,\n",
    "                        epochs=3,\n",
    "                        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5b88f9",
   "metadata": {},
   "source": [
    "### Training CNN with augmented data\n",
    "In the code below the variable `AUGMENTATION_FACTOR` can be changed to adapt the amount of augemented data used for training. For example, 0.75 means 75% augmented data and 25% original data. The generators for the augmented data are initialized with the autoencoder model as preprocessing function. This is done with the class `Model_transform`. This class is located in `main_util.py` and is responsible for augmenting the input of the data generators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d00ac93",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Define augmentation factor: choose 0.25 or 0.50 or 0.75 or 1\n",
    "AUGMENTATION_FACTOR = 0.75 \n",
    "\n",
    "# Defining model name and paths\n",
    "model_name = \"cnn_augmented_\" + str(AUGMENTATION_FACTOR)\n",
    "weights_filepath = f\"trained_models/{model_name}_weights.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1732663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the data generators for the augmented dataset  \n",
    "transformation = Model_transform(ae_model=model_ae, augmentation_factor=AUGMENTATION_FACTOR)\n",
    "train_gen_aug, val_gen_aug = get_pcam_generators(path, \n",
    "                                                 train_batch_size=16,\n",
    "                                                 val_batch_size=16,\n",
    "                                                 class_mode=\"binary\", \n",
    "                                                 prep_function=transformation.model_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7ec8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class instance is made\n",
    "model_cnn_aug = Model_architecture()\n",
    "model_cnn_aug.create_cnn(kernel_size=(3,3), pool_size=(4,4), first_filters=32, second_filters=64)\n",
    "model_cnn_aug.compile_cnn(learning_rate=0.001)\n",
    "\n",
    "# Prints a summary of the model structure\n",
    "model_cnn_aug.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32e9fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Tensorboard callback\n",
    "checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "tensorboard = TensorBoard(os.path.join(\"logs\", model_name))\n",
    "callbacks_list = [checkpoint, tensorboard]\n",
    "\n",
    "# Train the model\n",
    "train_steps = train_gen_aug.n//train_gen_aug.batch_size//10\n",
    "val_steps = val_gen_aug.n//val_gen_aug.batch_size//10\n",
    "\n",
    "history = model_cnn_aug.fit(train_gen_aug, steps_per_epoch=train_steps,\n",
    "                        validation_data=val_gen_aug,\n",
    "                        validation_steps=val_steps,\n",
    "                        epochs=30, \n",
    "                        callbacks=callbacks_list)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9862f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(20,7))\n",
    "\n",
    "# Make plot for accuracy\n",
    "ax[0].plot(history.history['accuracy'])\n",
    "ax[0].plot(history.history['val_accuracy'])\n",
    "ax[0].set_title('model accuracy')\n",
    "ax[0].set_ylabel('accuracy')\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[0].legend(['Train', 'Validation'], loc='upper left')\n",
    "ax[0].set_ylim([0, 1])\n",
    "\n",
    "# Make plot for loss\n",
    "ax[1].plot(history.history['loss'])\n",
    "ax[1].plot(history.history['val_loss'])\n",
    "ax[1].set_title('model loss')\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].legend(['Train', 'Validation'], loc='upper left')\n",
    "ax[1].set_ylim([0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a567115",
   "metadata": {},
   "source": [
    "This notebook can be used to obtain all the trained models, which are needed to run `main_project_notebook.ipynb` and `domain_generalization.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
