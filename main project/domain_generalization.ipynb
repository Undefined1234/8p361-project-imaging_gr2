{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAMELYON17 Dataset Evaluation\n",
    "This notebook covers the results using the CAMELYON17 dataset. This dataset includes image patches obtained from patients in multiple hospitals. The patches from different hospitals are used to evaluate the domain generalisation of the baseline CNN model compared to the CNN models trained with augmented data. First, the required libraries are loaded in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from main_util import Model_architecture\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras import backend\n",
    "from sklearn.metrics import roc_curve, auc, RocCurveDisplay\n",
    "\n",
    "metadata_path = \"../CAMELYON17 dataset/metadata.csv\"\n",
    "patch_folder_path = \"../CAMELYON17 dataset/patches\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `metadata.csv` file contains all the necessary information about the patches. The columns of this file contain: `index`, `patient number`, `node number`, `x-coordinate` w.r.t. the full WSI, `y-coordinate` w.r.t. the full WSI, `label`, `slide number`, `hospital` and `split number`. The metadata is split into the training and testing set based on the `split number`, where 0 is the training set and 1 the testing set. The columns of this csv file can be used later to easily get access to the correct folders, where the patches are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = np.genfromtxt(metadata_path, dtype=int, delimiter=\",\", skip_header=1)\n",
    "splitted_metadata = np.split(metadata, np.where(np.diff(metadata[:,8]))[0]+1)\n",
    "\n",
    "training_metadata = splitted_metadata[0]\n",
    "testing_metadata = splitted_metadata[1]\n",
    "for index in range(2, len(splitted_metadata)):\n",
    "    if index%2 == 0:\n",
    "        training_metadata = np.vstack((training_metadata, splitted_metadata[index]))\n",
    "    else:\n",
    "        testing_metadata = np.vstack((testing_metadata, splitted_metadata[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function `validation` is defined to perform the evaluation on the testing set. This can easily be done for different CNN models and different hospitals by changing the input arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(testing_metadata, model_filepath):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    testing_metadata:   an array containing the metadata of the testing set with the following columns:\n",
    "                        index, patient nr, node nr, x-coordinate, y-coordinate, label, slide nr, split nr\n",
    "    model_filepath:     filepath of the CNN model used to predict the patches.\n",
    "    \"\"\"\n",
    "    model = load_model(model_filepath)\n",
    "\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    for i in range(len(testing_metadata)):\n",
    "        patient_nr = testing_metadata[i,1]\n",
    "        node_nr = testing_metadata[i,2]\n",
    "        x_coord = testing_metadata[i,3]\n",
    "        y_coord = testing_metadata[i,4]\n",
    "            \n",
    "        if patient_nr < 10:\n",
    "             patch_path = f\"{patch_folder_path}/patient_00{patient_nr}_node_{node_nr}/patch_patient_00{patient_nr}_node_{node_nr}_x_{x_coord}_y_{y_coord}.png\"\n",
    "        else:\n",
    "            patch_path = f\"{patch_folder_path}/patient_0{patient_nr}_node_{node_nr}/patch_patient_0{patient_nr}_node_{node_nr}_x_{x_coord}_y_{y_coord}.png\"\n",
    "\n",
    "        img = img_to_array(load_img(patch_path, target_size=(96,96)))\n",
    "        img = np.array([img])\n",
    "            \n",
    "        pred_label = model.predict(img/255, verbose=None)\n",
    "        pred_labels.append(pred_label[0][0])\n",
    "\n",
    "        true_label = testing_metadata[i,5]\n",
    "        true_labels.append(true_label)\n",
    "\n",
    "        backend.clear_session()\n",
    "        if i%1000 == 0:\n",
    "            print(f\"Progress: {i}/{len(testing_metadata)}\")\n",
    "\n",
    "    return true_labels, pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0/45595\n",
      "Progress: 1000/45595\n"
     ]
    }
   ],
   "source": [
    "# Defining model name and paths\n",
    "model_name = \"cnn_baseline\"\n",
    "model_filepath = f\"trained_models/{model_name}.tf\"\n",
    "\n",
    "# Calling validation function\n",
    "true_labels, pred_labels = validation(testing_metadata, model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model name and paths\n",
    "model_name = \"cnn_augmented_25\"\n",
    "model_filepath = f\"trained_models/{model_name}.tf\"\n",
    "\n",
    "# Calling validation function\n",
    "true_labels_aug_25, pred_labels_aug_25 = validation(testing_metadata, model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model name and paths\n",
    "model_name = \"cnn_augmented_50\"\n",
    "model_filepath = f\"trained_models/{model_name}.tf\"\n",
    "\n",
    "# Calling validation function\n",
    "true_labels_aug_50, pred_labels_aug_50 = validation(testing_metadata, model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model name and paths\n",
    "model_name = \"cnn_augmented_75\"\n",
    "model_filepath = f\"trained_models/{model_name}.tf\"\n",
    "\n",
    "# Calling validation function\n",
    "true_labels_aug_75, pred_labels_aug_75 = validation(testing_metadata, model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model name and paths\n",
    "model_name = \"cnn_augmented_1\"\n",
    "model_filepath = f\"trained_models/{model_name}.tf\"\n",
    "\n",
    "# Calling validation function\n",
    "true_labels_aug_1, pred_labels_aug_1 = validation(testing_metadata, model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating false positive rate (fpr), true positive rate (tpr) and AUC\n",
    "fpr, tpr, thresholds = roc_curve(true_labels, pred_labels)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Generate ROC curve\n",
    "roc = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\n",
    "roc.plot();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "8p361gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
